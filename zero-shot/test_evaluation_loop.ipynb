{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from algorithms.feature_extraction_loading import FeatureDataset, extract_diffusion_features, feature_collate_fn, concatenate_video_features\n",
    "from evaluation.visualization import safe_heatmap_as_gif, place_marker_in_frames\n",
    "\n",
    "from evaluation.evaluation_datasets import compute_tapvid_metrics\n",
    "\n",
    "from algorithms.heatmap_generator import HeatmapGenerator\n",
    "from algorithms.zero_shot_tracker import ZeroShotTracker\n",
    "\n",
    "heatmap_generator = HeatmapGenerator()\n",
    "zero_shot_tracker = ZeroShotTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_diffusion_features(input_dataset_paths={'davis': '../tapvid_davis/tapvid_davis.pkl'}, diffusion_model_path='../text-to-video-ms-1.7b/', restrict_frame_size=False, max_frame_size=2**18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataset = FeatureDataset(feature_dataset_path='output/features/davis')\n",
    "feature_loader = DataLoader(feature_dataset, batch_size=1, collate_fn=feature_collate_fn)\n",
    "\n",
    "video_idx = 0\n",
    "\n",
    "for batch in feature_loader:\n",
    "    query_points = []\n",
    "    gt_occluded = []\n",
    "    gt_tracks = []\n",
    "    pred_tracks = []\n",
    "\n",
    "    for sample in batch:\n",
    "        video_features = concatenate_video_features(\n",
    "            {\n",
    "                #'up_block': sample['features']['up_block'][0:3], \n",
    "                'decoder_block': [sample['features']['decoder_block'][0]],\n",
    "            },\n",
    "            perform_pca = True,\n",
    "            n_components = 10\n",
    "        )\n",
    "\n",
    "        print(video_features.shape)\n",
    "\n",
    "        idx = random.randint(0, len(sample['query_points'][0]) - 1)\n",
    "        query_point = sample['query_points'][0][idx]\n",
    "        query_points.append(query_point[None, :])\n",
    "\n",
    "        occluded = sample['occluded'][0, idx]\n",
    "        gt_occluded.append(occluded[None])\n",
    "\n",
    "        gt_track = sample['target_points'][0, idx]\n",
    "        gt_tracks.append(gt_track[None])\n",
    "\n",
    "        folder_path = os.path.join('output', 'video_' + str(video_idx))\n",
    "        if os.path.exists(folder_path):\n",
    "            shutil.rmtree(folder_path)\n",
    "        os.makedirs(folder_path)\n",
    "        query_point_file_name = os.path.join(folder_path, 'query_point.txt')\n",
    "        with open(query_point_file_name, 'w') as query_point_file:\n",
    "            query_point_file.write(str(query_point))\n",
    "\n",
    "        video_features = video_features.permute(0, 2, 3, 1).float()\n",
    "        heatmaps = heatmap_generator.generate(video_features, (query_point[1], query_point[2], int(query_point[0])))\n",
    "        pred_track = zero_shot_tracker.track(heatmaps)\n",
    "\n",
    "        pred_tracks.append(pred_track.numpy()[None])\n",
    "\n",
    "        gt_track_switched = np.zeros_like(gt_track)\n",
    "        gt_track_switched[:, 1] = gt_track[:, 0]\n",
    "        gt_track_switched[:, 0] = gt_track[:, 1]\n",
    "\n",
    "        place_marker_in_frames(sample['video'].squeeze(), pred_track, ground_truth_tracks=gt_track_switched, folder_path=folder_path)\n",
    "        safe_heatmap_as_gif(heatmaps, True, sample['video'].squeeze(), folder_path=folder_path)\n",
    "\n",
    "        video_idx += 1\n",
    "\n",
    "    metrics = compute_tapvid_metrics(query_points=np.array(query_points), gt_occluded=np.array(gt_occluded), gt_tracks=np.array(gt_tracks), pred_occluded=np.array(gt_occluded), pred_tracks=np.array(pred_tracks), query_mode='strided')\n",
    "\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
