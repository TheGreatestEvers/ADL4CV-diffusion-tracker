{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonevers/miniconda3/envs/adl4cv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from algorithms.feature_extraction_loading import FeatureDataset, extract_diffusion_features, feature_collate_fn, concatenate_video_features\n",
    "from evaluation.visualization import safe_heatmap_as_gif, place_marker_in_frames\n",
    "\n",
    "from evaluation.evaluation_datasets import compute_tapvid_metrics\n",
    "\n",
    "from algorithms.heatmap_generator import HeatmapGenerator\n",
    "from algorithms.zero_shot_tracker import ZeroShotTracker\n",
    "\n",
    "import evaluation.visualization as v\n",
    "\n",
    "heatmap_generator = HeatmapGenerator()\n",
    "zero_shot_tracker = ZeroShotTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_diffusion_features(input_dataset_paths={'davis': '../tapvid_davis/tapvid_davis.pkl'}, diffusion_model_path='../text-to-video-ms-1.7b/', restrict_frame_size=False, max_frame_size=2**18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mode = \"pca\"\n",
    "\n",
    "feature_dataset = FeatureDataset(feature_dataset_path='output/features/davis')\n",
    "feature_loader = DataLoader(feature_dataset, batch_size=1, collate_fn=feature_collate_fn)\n",
    "\n",
    "video_idx = 0\n",
    "\n",
    "for batch in feature_loader:\n",
    "    query_points = []\n",
    "    gt_occluded = []\n",
    "    gt_tracks = []\n",
    "    pred_tracks = []\n",
    "\n",
    "    for sample in batch:\n",
    "        \n",
    "        if mode == \"pca\":\n",
    "            concat_downblock = concatenate_video_features(\n",
    "                {\n",
    "                    'down_block': sample['features']['down_block'][:]\n",
    "                },\n",
    "                perform_pca = True,\n",
    "                n_components = 20\n",
    "            )\n",
    "            concat_midblock = concatenate_video_features(\n",
    "                {\n",
    "                    'mid_block': sample['features']['mid_block'][:]\n",
    "                },\n",
    "                perform_pca = True,\n",
    "                n_components = 20\n",
    "            )\n",
    "            concat_upblock = concatenate_video_features(\n",
    "                {\n",
    "                    'up_block': sample['features']['up_block'][:]\n",
    "                },\n",
    "                perform_pca = True,\n",
    "                n_components = 20\n",
    "            )\n",
    "            concat_decoderblock = concatenate_video_features(\n",
    "                {\n",
    "                    'decoder_block': sample['features']['decoder_block'][:]\n",
    "                },\n",
    "                perform_pca = True,\n",
    "                n_components = 10\n",
    "            )\n",
    "        \n",
    "        elif mode == \"pooling\":\n",
    "            concat_downblock = concatenate_video_features(\n",
    "                {\n",
    "                    'down_block': sample['features']['down_block'][:]\n",
    "                },\n",
    "                perform_pooling = True\n",
    "            )\n",
    "            concat_midblock = concatenate_video_features(\n",
    "                {\n",
    "                    'mid_block': sample['features']['mid_block'][:]\n",
    "                },\n",
    "                perform_pooling = True\n",
    "            )\n",
    "            concat_upblock = concatenate_video_features(\n",
    "                {\n",
    "                    'up_block': sample['features']['up_block'][:]\n",
    "                },\n",
    "                perform_pooling = True\n",
    "            )\n",
    "            concat_decoderblock = concatenate_video_features(\n",
    "                {\n",
    "                    'decoder_block': sample['features']['decoder_block'][:]\n",
    "                },\n",
    "                perform_pooling = True\n",
    "            )\n",
    "\n",
    "        # WORSE PERFORMANCE!\n",
    "        # # Scale each tensor to [-1, 1]\n",
    "        # down_min = concat_downblock.min()\n",
    "        # down_max = concat_downblock.max()\n",
    "        # concat_downblock = (concat_downblock - down_min) / (down_max - down_min)\n",
    "        # #concat_downblock = concat_downblock * 2 - 1\n",
    "\n",
    "        # mid_min = concat_midblock.min()\n",
    "        # mid_max = concat_midblock.max()\n",
    "        # concat_midblock = (concat_midblock - mid_min) / (mid_max - mid_min)\n",
    "        # #concat_midblock = concat_midblock * 2 - 1\n",
    "\n",
    "        # up_min = concat_upblock.min()\n",
    "        # up_max = concat_upblock.max()\n",
    "        # concat_upblock = (concat_upblock - up_min) / (up_max - up_min)\n",
    "        # #concat_upblock = concat_upblock * 2 - 1\n",
    "    \n",
    "        # decoder_min = concat_decoderblock.min()\n",
    "        # decoder_max = concat_decoderblock.max()\n",
    "        # concat_decoderblock = (concat_decoderblock - decoder_min) / (decoder_max - decoder_min)\n",
    "        # #concat_decoderblock = concat_decoderblock * 2 - 1\n",
    "\n",
    "        # print(\"AFTER PCA:\")\n",
    "        # print(\"Feature map means:\")\n",
    "        # print(torch.mean(concat_downblock))\n",
    "        # print(torch.mean(concat_midblock))\n",
    "        # print(torch.mean(concat_upblock))\n",
    "        # print(torch.mean(concat_decoderblock))\n",
    "\n",
    "        # print(\"Feature map maxs:\")\n",
    "        # print(torch.max(concat_downblock))\n",
    "        # print(torch.max(concat_midblock))\n",
    "        # print(torch.max(concat_upblock))\n",
    "        # print(torch.max(concat_decoderblock))\n",
    "\n",
    "        video_features = concatenate_video_features(\n",
    "            {\n",
    "                'down_block': [concat_downblock],\n",
    "                'mid_block': [concat_midblock],\n",
    "                'up_block': [concat_upblock],\n",
    "                'decoder_block': [concat_decoderblock],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        idx = random.randint(0, len(sample['query_points'][0]) - 1)\n",
    "        query_point = sample['query_points'][0][idx]\n",
    "        query_points.append(query_point[None, :])\n",
    "\n",
    "        occluded = sample['occluded'][0, idx]\n",
    "        gt_occluded.append(occluded[None])\n",
    "\n",
    "        gt_track = sample['target_points'][0, idx]\n",
    "        gt_tracks.append(gt_track[None])\n",
    "\n",
    "        folder_path = os.path.join('output', 'video_' + str(video_idx))\n",
    "        if os.path.exists(folder_path):\n",
    "            shutil.rmtree(folder_path)\n",
    "        os.makedirs(folder_path)\n",
    "        query_point_file_name = os.path.join(folder_path, 'query_point.txt')\n",
    "        with open(query_point_file_name, 'w') as query_point_file:\n",
    "            query_point_file.write(str(query_point))\n",
    "\n",
    "        target = torch.tensor([[int(query_point[0]), query_point[1], query_point[2]]]) # Targets are now tensor in shape Nx3\n",
    "        heatmaps = heatmap_generator.generate(video_features, target, device=\"cpu\")\n",
    "\n",
    "        pred_track = zero_shot_tracker.track(heatmaps)\n",
    "\n",
    "        pred_tracks.append(pred_track.numpy()[None])\n",
    "\n",
    "        gt_track_switched = np.zeros_like(gt_track)\n",
    "        gt_track_switched[:, 1] = gt_track[:, 0]\n",
    "        gt_track_switched[:, 0] = gt_track[:, 1]\n",
    "\n",
    "        v.place_marker_in_frames(sample['video'].squeeze(), pred_track, ground_truth_tracks=gt_track_switched, folder_path=folder_path)\n",
    "        v.safe_heatmap_as_gif(heatmaps, True, sample['video'].squeeze(), folder_path=folder_path)\n",
    "\n",
    "        video_idx += 1\n",
    "\n",
    "    #metrics = compute_tapvid_metrics(query_points=np.array(query_points), gt_occluded=np.array(gt_occluded), gt_tracks=np.array(gt_tracks), pred_occluded=np.array(gt_occluded), pred_tracks=np.array(pred_tracks), query_mode='strided')\n",
    "\n",
    "    #print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['up_block', 'down_block', 'mid_block', 'decoder_block'])\n",
      "up_block\n",
      "avg:\n",
      "tensor(-0.0637, dtype=torch.float16)\n",
      "max:\n",
      "tensor(284.7500, dtype=torch.float16)\n",
      "down_block\n",
      "avg:\n",
      "tensor(-0.3726, dtype=torch.float16)\n",
      "max:\n",
      "tensor(98.2500, dtype=torch.float16)\n",
      "mid_block\n",
      "avg:\n",
      "tensor(-0.5400, dtype=torch.float16)\n",
      "max:\n",
      "tensor(77.6875, dtype=torch.float16)\n",
      "decoder_block\n",
      "avg:\n",
      "tensor(0.5352, dtype=torch.float16)\n",
      "max:\n",
      "tensor(6688., dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Check mean and max of featuremaps before pca\n",
    "\n",
    "featuremapssss = sample[\"features\"]\n",
    "print(featuremapssss.keys())\n",
    "\n",
    "for (key, value) in sample[\"features\"].items():\n",
    "    concat_block = concatenate_video_features(\n",
    "        {\n",
    "            'x': value[:]\n",
    "        }\n",
    "    )\n",
    "    print(key)\n",
    "    print(\"avg:\")\n",
    "    print(torch.mean(concat_block))\n",
    "    print(\"max:\")\n",
    "    print(torch.max(concat_block))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use decoder for upsampling\n",
    "\n",
    "feature_dataset = FeatureDataset(feature_dataset_path='output/features/davis')\n",
    "feature_loader = DataLoader(feature_dataset, batch_size=1, collate_fn=feature_collate_fn)\n",
    "\n",
    "video_idx = 0\n",
    "\n",
    "for batch in feature_loader:\n",
    "    query_points = []\n",
    "    gt_occluded = []\n",
    "    gt_tracks = []\n",
    "    pred_tracks = []\n",
    "\n",
    "    for sample in batch:\n",
    "          \n",
    "        concat_upblock = concatenate_video_features(\n",
    "            {\n",
    "                'up_block': sample['features']['up_block'][:]\n",
    "            },\n",
    "            perform_pca = True,\n",
    "            n_components = 4\n",
    "        )\n",
    "\n",
    "        ###\n",
    "        HIER DECODER REINLADEN UND EIN FORWARDPASS\n",
    "        ###\n",
    "\n",
    "        #idx = random.randint(0, len(sample['query_points'][0]) - 1)\n",
    "        query_point = sample['query_points'][0][idx]\n",
    "        query_points.append(query_point[None, :])\n",
    "\n",
    "        occluded = sample['occluded'][0, idx]\n",
    "        gt_occluded.append(occluded[None])\n",
    "\n",
    "        gt_track = sample['target_points'][0, idx]\n",
    "        gt_tracks.append(gt_track[None])\n",
    "\n",
    "        folder_path = os.path.join('output', 'video_' + str(video_idx))\n",
    "        if os.path.exists(folder_path):\n",
    "            shutil.rmtree(folder_path)\n",
    "        os.makedirs(folder_path)\n",
    "        query_point_file_name = os.path.join(folder_path, 'query_point.txt')\n",
    "        with open(query_point_file_name, 'w') as query_point_file:\n",
    "            query_point_file.write(str(query_point))\n",
    "\n",
    "        target = torch.tensor([[int(query_point[0]), query_point[1], query_point[2]]]) # Targets are now tensor in shape Nx3\n",
    "        heatmaps = heatmap_generator.generate(video_features, target, device=\"cpu\")\n",
    "\n",
    "        pred_track = zero_shot_tracker.track(heatmaps)\n",
    "\n",
    "        pred_tracks.append(pred_track.numpy()[None])\n",
    "\n",
    "        gt_track_switched = np.zeros_like(gt_track)\n",
    "        gt_track_switched[:, 1] = gt_track[:, 0]\n",
    "        gt_track_switched[:, 0] = gt_track[:, 1]\n",
    "\n",
    "        v.place_marker_in_frames(sample['video'].squeeze(), pred_track, ground_truth_tracks=gt_track_switched, folder_path=folder_path)\n",
    "        v.safe_heatmap_as_gif(heatmaps, True, sample['video'].squeeze(), folder_path=folder_path)\n",
    "\n",
    "        video_idx += 1\n",
    "\n",
    "    #metrics = compute_tapvid_metrics(query_points=np.array(query_points), gt_occluded=np.array(gt_occluded), gt_tracks=np.array(gt_tracks), pred_occluded=np.array(gt_occluded), pred_tracks=np.array(pred_tracks), query_mode='strided')\n",
    "\n",
    "    #print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
